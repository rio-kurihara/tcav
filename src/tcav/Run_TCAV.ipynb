{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running TCAV\n",
    "\n",
    "\n",
    "This notebook walks you through things you need to run TCAV. In high level, you need:\n",
    "\n",
    "1. **example images in each folder**\n",
    " * images for each concept\n",
    " * images for the class/labels of interest\n",
    " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
    "2. **model wrapper**: an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
    "3. **act_generator**: an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
    "\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "    pip install the tcav and tensorflow packages (or tensorflow-gpu if using GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Store concept and target class images to local folders\n",
    "\n",
    "and tell TCAV where they are.\n",
    "\n",
    "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
    "\n",
    "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
    "\n",
    "\n",
    "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
    "\n",
    "\n",
    "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
    "\n",
    "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
    "\n",
    "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO UPDATE FOLDER PREFIX!\n"
     ]
    }
   ],
   "source": [
    "# folder prefix \n",
    "# Mac\n",
    "prefix = '/Users/beenkim'\n",
    "# Ubuntu\n",
    "prefix = '/usr/local/google/home/beenkim'\n",
    "\n",
    "print ('REMEMBER TO UPDATE FOLDER PREFIX!')\n",
    "\n",
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'GoogleNet'  \n",
    "user = 'beenkim'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + user + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir+ '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live. \n",
    "source_dir = prefix + \"/image_net_subsets/\"\n",
    "bottlenecks = [ 'mixed4c']  # @param \n",
    "      \n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "target = 'zebra'  \n",
    "concepts = [\"dotted\",\"striped\",\"zigzagged\"]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottlenecks = [ 'mixed5b']  # @param \n",
    "\n",
    "\n",
    "# 概念画像、ターゲットクラス、ランダム画像（CAVを学習する際の負のサンプル）が存在するディレクトリ\n",
    "# それぞれがこのディレクトリ内のサブフォルダである必要があります。\n",
    "# ランダム画像ディレクトリは任意の名前にすることができます。 この例では、任意の理由でrandom500_0、random500_1などを使用しています。\n",
    "source_dir = '/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/'\n",
    "\n",
    "activation_dir = '/home/rio.kurihara/advent_calender_191224/activations'\n",
    "working_dir = '/home/rio.kurihara/advent_calender_191224'\n",
    "# CAVを保存するディレクトリ（保存しない場合はなし）\n",
    "cav_dir = '/home/rio.kurihara/advent_calender_191224'\n",
    "\n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "# ターゲット、概念：ターゲットクラスの名前（調査する）および概念（文字列）-これらはsource_dirのフォルダー名です\n",
    "target = 'hibany'  \n",
    "concepts = [\"black\",\"red\",\"yellow\", 'blue', 'white']   \n",
    "\n",
    "# ボトルネック：TCAVに使用するボトルネック名（モデルの中間層）のリスト。 これらの名前は、以下のモデルラッパーで定義されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Write your model wrapper\n",
    "\n",
    "Next step is to tell TCAV how to communicate with your model. See `model.GoolgeNetWrapper_public ` for details.\n",
    "\n",
    "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
    "\n",
    "### 1. Tensors from the graph: bottleneck tensors and ends\n",
    "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
    "\n",
    "### 2. Define loss\n",
    "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
    "\n",
    "While doing so, you would also want to set \n",
    "```python\n",
    "self.y_input \n",
    "```\n",
    "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
    "For multi-class classification, typically something like this works:\n",
    "\n",
    "```python\n",
    "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "```\n",
    "\n",
    "For example, for a multiclass classifier, something like below would work. \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 3. Call _make_gradient_tensors in __init__() of your wrapper\n",
    "```python\n",
    "_make_gradient_tensors()  \n",
    "```\n",
    "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
    "\n",
    "### 4. Fill in labels, image shapes and a model name.\n",
    "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
    "\n",
    "```python\n",
    "def id_to_label(self, idx)\n",
    "def label_to_id(self, label)\n",
    "```\n",
    "\n",
    "Set your input image shape at  `self.image_shape`\n",
    "\n",
    "\n",
    "Set your model name to `self.model_name`\n",
    "\n",
    "You are done with writing the model wrapper! I wrote two model wrapers, InceptionV3 and Googlenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**sess**: a tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rio.kurihara/advent_calender_191224/tcav-master/tcav/model.py:275: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH =  '../models/tensorflow_inception_graph.pb'\n",
    "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
    "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
    "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
    "# dummy                                                                                      \n",
    "# kit fox\n",
    "# English setter\n",
    "# Siberian husky ...\n",
    "\n",
    "# LABEL_PATH = prefix + \"/trained_models/google_net_inception_v1/imagenet_comp_graph_label_strings.txt\"\n",
    "LABEL_PATH = '../datasets/source_tcav/label.txt'\n",
    "\n",
    "\n",
    "mymodel = model.GoolgeNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed3a': <tf.Tensor 'v1/mixed3a:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
       " 'mixed3b': <tf.Tensor 'v1/mixed3b:0' shape=(?, ?, ?, 480) dtype=float32>,\n",
       " 'mixed4a': <tf.Tensor 'v1/mixed4a:0' shape=(?, ?, ?, 508) dtype=float32>,\n",
       " 'mixed4b': <tf.Tensor 'v1/mixed4b:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " 'mixed4c': <tf.Tensor 'v1/mixed4c:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " 'mixed4d': <tf.Tensor 'v1/mixed4d:0' shape=(?, ?, ?, 528) dtype=float32>,\n",
       " 'mixed4e': <tf.Tensor 'v1/mixed4e:0' shape=(?, ?, ?, 832) dtype=float32>,\n",
       " 'mixed5a': <tf.Tensor 'v1/mixed5a:0' shape=(?, ?, ?, 832) dtype=float32>,\n",
       " 'mixed5b': <tf.Tensor 'v1/mixed5b:0' shape=(?, ?, ?, 1024) dtype=float32>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.bottlenecks_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Implement a class that returns activations (maybe with caching!)\n",
    "\n",
    "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
    "\n",
    "\n",
    "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
    "\n",
    "```python\n",
    "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
    "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
    "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You are ready to run TCAV!\n",
    "\n",
    "Let's do it.\n",
    "\n",
    "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
    "\n",
    "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This may take a while... Go get coffee!\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/random500_1\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "/home/rio.kurihara/advent_calender_191224/datasets/source_tcav/hibany\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(0)\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "mytcav = tcav.TCAV(sess,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_generator,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "#                    num_random_exp=10)\n",
    "                   num_random_exp=2)\n",
    "\n",
    "print ('This may take a while... Go get coffee!')\n",
    "results = mytcav.run(run_parallel=False)\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed3a': <tf.Tensor 'v1/mixed3a:0' shape=(?, ?, ?, 256) dtype=float32>,\n",
       " 'mixed3b': <tf.Tensor 'v1/mixed3b:0' shape=(?, ?, ?, 480) dtype=float32>,\n",
       " 'mixed4a': <tf.Tensor 'v1/mixed4a:0' shape=(?, ?, ?, 508) dtype=float32>,\n",
       " 'mixed4b': <tf.Tensor 'v1/mixed4b:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " 'mixed4c': <tf.Tensor 'v1/mixed4c:0' shape=(?, ?, ?, 512) dtype=float32>,\n",
       " 'mixed4d': <tf.Tensor 'v1/mixed4d:0' shape=(?, ?, ?, 528) dtype=float32>,\n",
       " 'mixed4e': <tf.Tensor 'v1/mixed4e:0' shape=(?, ?, ?, 832) dtype=float32>,\n",
       " 'mixed5a': <tf.Tensor 'v1/mixed5a:0' shape=(?, ?, ?, 832) dtype=float32>,\n",
       " 'mixed5b': <tf.Tensor 'v1/mixed5b:0' shape=(?, ?, ?, 1024) dtype=float32>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.bottlenecks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = hibany\n",
      "  Concept = red\n",
      "    Bottleneck = mixed5b. TCAV Score = 0.40 (+- 0.00), random was 0.43 (+- 0.17). p-val = 0.860 (not significant)\n",
      "  Concept = yellow\n",
      "    Bottleneck = mixed5b. TCAV Score = 0.53 (+- 0.07), random was 0.43 (+- 0.17). p-val = 0.633 (not significant)\n",
      "  Concept = blue\n",
      "    Bottleneck = mixed5b. TCAV Score = 0.53 (+- 0.00), random was 0.43 (+- 0.17). p-val = 0.609 (not significant)\n",
      "  Concept = black\n",
      "    Bottleneck = mixed5b. TCAV Score = 0.70 (+- 0.10), random was 0.43 (+- 0.17). p-val = 0.304 (not significant)\n",
      "  Concept = white\n",
      "    Bottleneck = mixed5b. TCAV Score = 0.57 (+- 0.10), random was 0.43 (+- 0.17). p-val = 0.564 (not significant)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-70fd73780c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_random_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/advent_calender_191224/tcav-master/tcav/utils_plot.py\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(results, random_counterpart, random_concepts, num_random_exp, min_p_val)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         bar = ax.bar(index + i * bar_width, vals['bn_vals'],\n\u001b[0;32m--> 143\u001b[0;31m                      bar_width, yerr=vals['bn_stds'], label=bn)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# draw stars to mark bars that are stastically insignificant to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2241\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2242\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2243\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 0.1,\n",
       "  'bottleneck': 'mixed5b',\n",
       "  'cav_accuracies': {'black': 1.0, 'overall': 1.0, 'random500_0': 1.0},\n",
       "  'cav_concept': 'black',\n",
       "  'cav_key': 'black-random500_0-mixed5b-linear-0.1',\n",
       "  'i_up': 0.8,\n",
       "  'negative_concept': 'random500_0',\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'target_class': 'hibany',\n",
       "  'val_directional_dirs': [-5.3476084060724345e-05,\n",
       "   -1.993784669675321e-06,\n",
       "   -4.197100911654277e-06,\n",
       "   -2.097322398709209e-05,\n",
       "   -1.6226785437169863e-05,\n",
       "   -1.5533423726122774e-05,\n",
       "   -7.366324671873315e-06,\n",
       "   -2.6934014429046994e-05,\n",
       "   -9.70486816951523e-06,\n",
       "   -1.641470172408347e-05,\n",
       "   -2.5069496474917766e-06,\n",
       "   8.911421335263955e-06,\n",
       "   1.5793525564910114e-05,\n",
       "   2.7278628324841022e-06,\n",
       "   -0.00011790024602096885],\n",
       "  'val_directional_dirs_abs_mean': 2.1377354479205096e-05,\n",
       "  'val_directional_dirs_mean': -1.7719646514850676e-05,\n",
       "  'val_directional_dirs_std': 3.109377209735649e-05},\n",
       " {'alpha': 0.1,\n",
       "  'bottleneck': 'mixed5b',\n",
       "  'cav_accuracies': {'overall': 1.0, 'random500_0': 1.0, 'red': 1.0},\n",
       "  'cav_concept': 'red',\n",
       "  'cav_key': 'red-random500_0-mixed5b-linear-0.1',\n",
       "  'i_up': 0.4,\n",
       "  'negative_concept': 'random500_0',\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'target_class': 'hibany',\n",
       "  'val_directional_dirs': [2.740045428389687e-05,\n",
       "   3.6429522826353264e-06,\n",
       "   9.702809368097454e-07,\n",
       "   -1.561523366205332e-05,\n",
       "   -3.045191678682748e-05,\n",
       "   -1.3116056070468021e-06,\n",
       "   1.452864491332429e-06,\n",
       "   -3.658237130230354e-05,\n",
       "   6.950320938890232e-06,\n",
       "   -3.864218806678109e-05,\n",
       "   8.465146241680139e-06,\n",
       "   1.8608330903220446e-05,\n",
       "   2.799035904293417e-05,\n",
       "   1.555868510966445e-05,\n",
       "   -0.00010142069954069775],\n",
       "  'val_directional_dirs_abs_mean': 2.2337560613118255e-05,\n",
       "  'val_directional_dirs_mean': -7.532308048976413e-06,\n",
       "  'val_directional_dirs_std': 3.235054225490064e-05},\n",
       " {'alpha': 0.1,\n",
       "  'bottleneck': 'mixed5b',\n",
       "  'cav_accuracies': {'overall': 0.9230769230769231,\n",
       "   'random500_0': 1.0,\n",
       "   'yellow': 0.8571428571428571},\n",
       "  'cav_concept': 'yellow',\n",
       "  'cav_key': 'yellow-random500_0-mixed5b-linear-0.1',\n",
       "  'i_up': 0.4666666666666667,\n",
       "  'negative_concept': 'random500_0',\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'target_class': 'hibany',\n",
       "  'val_directional_dirs': [1.983275672382719e-05,\n",
       "   -6.14492431848231e-06,\n",
       "   -1.1158320115887692e-06,\n",
       "   -7.068881398780038e-06,\n",
       "   -6.0075643910468866e-05,\n",
       "   9.960789305393024e-06,\n",
       "   8.179668181382035e-07,\n",
       "   -2.98699424063698e-06,\n",
       "   4.873765739467829e-07,\n",
       "   2.5944112183360885e-05,\n",
       "   -2.7380310120506642e-05,\n",
       "   1.3291112797039992e-05,\n",
       "   2.8552751702050514e-05,\n",
       "   4.470534422786931e-07,\n",
       "   -0.00011488867044886384],\n",
       "  'val_directional_dirs_abs_mean': 2.1266345066357516e-05,\n",
       "  'val_directional_dirs_mean': -8.021822460219479e-06,\n",
       "  'val_directional_dirs_std': 3.5449019848689355e-05},\n",
       " {'alpha': 0.1,\n",
       "  'bottleneck': 'mixed5b',\n",
       "  'cav_accuracies': {'blue': 1.0, 'overall': 0.9, 'random500_0': 0.8},\n",
       "  'cav_concept': 'blue',\n",
       "  'cav_key': 'blue-random500_0-mixed5b-linear-0.1',\n",
       "  'i_up': 0.5333333333333333,\n",
       "  'negative_concept': 'random500_0',\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'target_class': 'hibany',\n",
       "  'val_directional_dirs': [5.776068506218276e-05,\n",
       "   -5.604757424967163e-06,\n",
       "   -2.277998816603172e-06,\n",
       "   -9.25934710338537e-06,\n",
       "   7.960492655881015e-05,\n",
       "   1.1438170914334255e-05,\n",
       "   -2.3000897950127947e-05,\n",
       "   -1.0895149147161596e-05,\n",
       "   6.712834368498226e-06,\n",
       "   -2.2664687830739636e-05,\n",
       "   -2.01836471851901e-05,\n",
       "   1.013104007725397e-05,\n",
       "   2.6333798166379873e-05,\n",
       "   7.4122281692440556e-06,\n",
       "   -4.2795864187993016e-05],\n",
       "  'val_directional_dirs_abs_mean': 2.2405068864191418e-05,\n",
       "  'val_directional_dirs_mean': 4.180755578035685e-06,\n",
       "  'val_directional_dirs_std': 3.0507528679655966e-05},\n",
       " {'alpha': 0.1,\n",
       "  'bottleneck': 'mixed5b',\n",
       "  'cav_accuracies': {'overall': 0.8571428571428571,\n",
       "   'random500_0': 0.8571428571428571,\n",
       "   'white': 0.8571428571428571},\n",
       "  'cav_concept': 'white',\n",
       "  'cav_key': 'white-random500_0-mixed5b-linear-0.1',\n",
       "  'i_up': 0.6666666666666666,\n",
       "  'negative_concept': 'random500_0',\n",
       "  'note': 'alpha_0.1 ',\n",
       "  'target_class': 'hibany',\n",
       "  'val_directional_dirs': [5.148406730766383e-05,\n",
       "   7.3663325412084585e-06,\n",
       "   -1.0817989194136904e-06,\n",
       "   -8.965260522302473e-06,\n",
       "   4.864116083407856e-05,\n",
       "   5.01856938457073e-06,\n",
       "   -2.5649566991116128e-05,\n",
       "   -2.35653880752558e-05,\n",
       "   -2.8413507699588973e-06,\n",
       "   -6.057706763905929e-05,\n",
       "   3.202975295993635e-06,\n",
       "   -1.7192756992044287e-06,\n",
       "   -1.4433881669469524e-05,\n",
       "   -3.0228612140456013e-06,\n",
       "   -0.00012590145991566007],\n",
       "  'val_directional_dirs_abs_mean': 2.5564734451933405e-05,\n",
       "  'val_directional_dirs_mean': -1.0136320403464713e-05,\n",
       "  'val_directional_dirs_std': 4.050443705847927e-05}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n",
      "red\n",
      "yellow\n",
      "blue\n",
      "white\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result['cav_concept'])\n",
    "# result['cav_concept']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
