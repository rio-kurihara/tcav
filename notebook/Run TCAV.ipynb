{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCAVの実行\n",
    "\n",
    "\n",
    "このNotebookでは、TCAVの実行手順を説明します。以下が必要です。\n",
    "\n",
    "1. **各フォルダーのサンプル画像の用意**\n",
    " * 概念画像\n",
    " * 調査したいクラス/ラベルの画像\n",
    " * CAVを学習するときの負例となるランダムな画像（どの概念にも属さないであろう画像）\n",
    "2. **model wrapperの作成**：ModelWrapper抽象クラスのインスタンス（model.py内）.TCAVクラス（tcav.py）にモデルと通信する方法を指示する\n",
    "3. **act_generatorの作成**：モデルからアクティベーションを取得する方法をTCAVクラスに伝えるActivationGeneratorInterfaceのインスタンス\n",
    "\n",
    "\n",
    "## 要件\n",
    "    pipでtcavとtensorflow（もしくはtensorflow-gpu）をインストール  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ1. 概念画像およびターゲットクラスの画像をディレクトリに保存する\n",
    "\n",
    "画像を準備したら、パスを設定する。\n",
    "\n",
    "**source_dir**：概念画像、ターゲットクラスの画像、ランダム画像が存在する場所  \n",
    "それぞれ、source_dir内のサブフォルダである必要があります。  \n",
    "ランダム画像ディレクトリは任意の名前にすることができます。 この例では、任意の理由で「random500_0」、「random500_1」を使用しています。  \n",
    "概念画像とターゲットクラスごとに約50〜200枚の画像が必要です（10〜20枚の画像も動作する傾向がありますが、200枚はかなり安全です）。  \n",
    "\n",
    "\n",
    "**cav_dir**：CAVを保存するディレクトリ（保存しない場合は `None`）  \n",
    "\n",
    "**ターゲット、概念**：調査したいターゲットクラスの名前と概念（文字列）  \n",
    "これらはsource_dirのフォルダー名です。\n",
    "\n",
    "**ボトルネック**：TCAVに使用するボトルネック名（モデルの中間層）のリスト  \n",
    "これらの名前は、モデルラッパーで定義されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 概念画像、ターゲットクラス、ランダム画像（CAVを学習する際の負のサンプル）が存在するディレクトリ\n",
    "# それぞれがこのディレクトリ内のサブフォルダである必要があります。\n",
    "# ランダム画像ディレクトリは任意の名前にすることができます。 この例では、任意の理由でrandom500_0、random500_1などを使用しています。\n",
    "source_dir = '../datasets/for_tcav/'\n",
    "activation_dir = '../activations'\n",
    "# CAVを保存するディレクトリ（保存しない場合はなし）\n",
    "cav_dir = '../cav'\n",
    "\n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "# ターゲット、概念：ターゲットクラスの名前（調査する）および概念（文字列）-これらはsource_dirのフォルダー名です\n",
    "concepts = [\"black\",\"red\",\"yellow\", 'blue', 'white', 'green']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ2. モデルラッパーを記述する\n",
    "\n",
    "次のステップは、モデルと通信する方法をTCAVに伝えることです。詳細については、「model.GoolgeNetWrapper_public」を参照してください。  \n",
    "https://github.com/tensorflow/tcav/blob/master/tcav/model.py#L333\n",
    "\n",
    "ModelWrapper抽象クラスのサブクラスを定義できます。各関数が何をするか説明します（これらはかなり自明です）。  \n",
    "このラッパーには、たとえば「get_prediction」など、すでに持っている多くの関数が含まれています。\n",
    "\n",
    "### 1. Tensors from the graph: bottleneck tensors and ends\n",
    "まず、ボトルネックテンソルを辞書として「self.bottlenecks_tensors」に保存します。 TCAVの実行に関心のあるボトルネックのみが必要です。同様に、「self.ends」辞書に「input」、「logit」、「prediction」テンソルを入力します。\n",
    "\n",
    "### 2. 損失を定義する\n",
    "損失テンソルを取得し、それを「self.loss」に割り当てます。これは、TCAVが方向導関数を取得するために使用するものです。\n",
    "\n",
    "```python\n",
    "self.y_input\n",
    "```\n",
    "これは、単にロジットレイヤーのターゲットインデックスのテンソルフロープレースホルダーです（たとえば、犬の場合はインデックス0、猫の場合はインデックス1）。\n",
    "マルチクラス分類の場合、通常、次のように機能します。\n",
    "```python\n",
    "self.y_input = tf.placeholder（tf.int64、shape = [None]）\n",
    "```\n",
    "\n",
    "たとえば、マルチクラス分類子の場合、次のようなものが機能します。  \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 3.ラッパーの__init __（）で_make_gradient_tensorsを呼び出す\n",
    "```python\n",
    "_make_gradient_tensors（）\n",
    "```\n",
    "上記で定義された損失とボトルネックのテンソルが与えられると、勾配テンソルを追加します。\n",
    "\n",
    "### 4.ラベル、画像の形、モデル名を入力します。\n",
    "辞書形式のラベル（文字列）からロジットレイヤー（int）のインデックスへのマッピングを取得します。\n",
    "\n",
    "```python\n",
    "def id_to_label（self、idx）\n",
    "def label_to_id（self、label）\n",
    "```\n",
    "\n",
    "入力画像の形状を「self.image_shape」に設定します\n",
    "\n",
    "モデル名を「self.model_name」に設定します\n",
    "\n",
    "モデルラッパーの作成はこれで完了です！InceptionV3とGooglenetの2つのモデルラッパーを作成しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**sess**: a tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = utils.create_session()\n",
    "\n",
    "GRAPH_PATH = '../models/model_op24/frozen_model.pb'\n",
    "LABEL_PATH = '../datasets/for_tcav/label.txt'\n",
    "    \n",
    "mymodel = model.SimepleCNNWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステップ3. アクティベーションを返すクラスを実装\n",
    "\n",
    "最後に、TCAVが特定の概念またはターゲットのサンプルデータをロードし、モデルラッパーを呼び出してアクティベーションを返すために使用するActivationGenerationInterfaceのクラスを実装します。このステップは多くの場合最も時間がかかるため、このロジックをmymodelの外部に引き出しました。モジュール化することで、アクティベーションをキャッシュしたり、計算を並列化したりできます。\n",
    "\n",
    "アクティベーションジェネレータの `process_and_load_activations`メソッドは、最初のキーとして概念名またはターゲット名を持ち、2番目のキーとしてボトルネック名を持つアクティベーションの辞書を返す必要があります。：\n",
    "\n",
    "```python\n",
    "{concept1：{bottleneck1：[[0.2、0.1、....]]}、\n",
    "concept2：{bottleneck1：[[0.1、0.02、....]]}、\n",
    "target1：{bottleneck1：[[0.02、0.99、....]]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCAV実行の準備完了\n",
    "\n",
    "**num_random_exp**：意味のある概念の方向を確認するための実験の数。TCAVは、`random500_0`、` random500_1`などの名前のこのフォルダーを検索します。代わりに、`random_concepts`キーワードをランダムな概念のフォルダーのリストに設定することもできます。 有意義なテストを行うには、少なくとも10〜20を実行します。\n",
    "\n",
    "**random_counterpart**：上記と同様に、オプションで統計テストの「ポジティブセット」としてランダム画像を含む単一のフォルダーを提供できます。 信頼性の低いランダムTCAVスコアを犠牲にして、計算時間を短縮します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.bottlenecks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(0)\n",
    "target = 'messon'  \n",
    "# ボトルネック：TCAVに使用するボトルネック名（モデルの中間層）のリスト\n",
    "# bottlenecks = ['conv2d_1', 'conv2d_3', 'conv2d_4', 'dense_2']\n",
    "bottlenecks = ['activation_5']\n",
    "\n",
    "num_random_exp = 3\n",
    "\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "mytcav = tcav.TCAV(sess,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_generator,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "                   num_random_exp=num_random_exp)\n",
    "print ('This may take a while... Go get coffee!')\n",
    "results = mytcav.run(run_parallel=True)\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
